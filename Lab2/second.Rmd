---
title: "Лабораторная работа №2"
author: "Usov Danil"
date: "17 05 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Тема №1: Точечные оценки параметров методом моментов
Цель работы − научиться генерировать выборки с заданными параметрами и определять точечные оценки параметров выборок методом моментов.

### 1. Нормальный закон распределения.

Сгенерируем выборку:
```{r}
x1 = rnorm(788, 59, 69)
str(x1)
```
Найдём оценки неизвестных параметров:
```{r}
a = mean(x1); a
si = sd(x1); si
```

### 2. Показательный закон распределения.

Сгенерируем выборку:
```{r}
x2 = rexp(700, 27)
str(x2)
```
Найдём оценки неизвестных параметров:
```{r}
lam = 1 / mean(x2); lam
```

### 3. Биномиальный закон распределения.

Сгенерируем выборку:
```{r}
x3 = rbinom(700, 42, 0.8)
str(x3)
```
Найдём оценки неизвестных параметров:
```{r}
p = mean(x3) / 20; p
n = mean(x3) / 0.6; n
```
Вычисленные оценки отличаются от заданных параметров. При показательном законе распределения эти отличия невелики, при нормальном и биномиальном же законах распределения вычисленные оценки отличаются в большей степени.

## Тема №2: Сравнение способов оценивания
Целью лабораторной работы является изучение трех способов статистического оценивания: оценка, полуенная методом моментов; оценка, полученная методом максимального правдоподобия; оценка, полученная методом порядковых статистик.
```{r}
# Функции нахождения оценок
moments = function(n) { 
  return (function (x) (2 / n) * sum(x));
}
likelihood = function(n) {
  return (function (x) ((n + 1) / n) * max(x))
}
ordinal = function(n) {
  return (function (x) (2 * quantile(x, c(0.5))))
}
nList <- list(10, 40, 160)
varCount <- 20
m <- 15 + 2*22
s <- 3 + 3*22
l <- 5 + 22
myNorm = function(n){
  return(rnorm(n, m, s))
}
myExp = function(n){
  return(rexp(n, l))
}
foo = myNorm
isNorm <- TRUE
for (i in 1:2){
  sdMatrix <- matrix(0, nrow = 3, ncol = 3)
  for (i in 1:3){
    n <- nList[[i]]
    print("-----------------------")
    str(n)
    # Генерация матрицы по установленному закону распределения
    xs = foo(n * varCount)
    M <- matrix(xs, varCount, n)
    
    # Вычисление значений оценок
    rez1 <- apply(M, 1, moments(n))
    rez2 <- apply(M, 1, likelihood(n))
    rez3 <- apply(M, 1, ordinal(n))
    print("Оценки:")
    str(rez1)
    str(rez2)
    str(rez3)
    
    print("Среднеквадратическое отклонение")
    p1 <- sd(rez1); str(p1)
    p2 <- sd(rez2); str(p2)
    p3 <- sd(rez3); str(p3)
    sdMatrix[i, 1] <- p1
    sdMatrix[i, 2] <- p2
    sdMatrix[i, 3] <- p3
    
    print("Максимальное значение")
    max1 <- max(rez1); str(max1)
    max2 <- max(rez2); str(max2)
    max3 <- max(rez3); str(max3)
    
    print("Минимальное значение")
    min1 <- min(rez1); str(min1)
    min2 <- min(rez2); str(min2)
    min3 <- min(rez3); str(min3)
    
    print("Величина размаха")
    r1 <- max1 - min1; str(r1)
    r2 <- max2 - min2; str(r2)
    r3 <- max3 - min3; str(r3)
    
    # Построение графиков получившихся оценок
    plot ( rez1 , col = " red ")
    lines ( rez1 , col = " red")
    par ( new =T )
    plot ( rez2 , col = " blue ")
    lines ( rez2 , col = " blue ")
    par ( new =T )
    plot ( rez3 , col = " yellow ")
    lines ( rez3 , col = " yellow ")
    par ( new =F )
  }
  # Построение графика отклонений
  valsMoments <- c(sdMatrix[1, 1], sdMatrix[2,1], sdMatrix[3,1])
  valsLikelihood <- c(sdMatrix[1, 2], sdMatrix[2,2], sdMatrix[3,2])
  valsOrdinal <- c(sdMatrix[1, 3], sdMatrix[2,3], sdMatrix[3,3])
  plot ( valsMoments , col = " red ")
  lines ( valsMoments , col = " red")
  par ( new =T )
  plot ( valsLikelihood , col = " blue ")
  lines ( valsLikelihood , col = " blue ")
  par ( new =T )
  plot ( valsOrdinal , col = " yellow ")
  lines ( valsOrdinal , col = " yellow ")
  par ( new =F )
  
  # Смена на показательный закон распределения
  foo = myExp
  if (isNorm){
    print("Показательный закон распределения")
    isNorm <- FALSE
  }
}
```

Исходя из результатов можно сделать вывод, что на небольших выборках большей точностью обладает метод порядковых статистик, а при увеличении объёма выборки метод моментов и метод максимального правдоподобия дают более точную оценку.

## Тема №3: Проверка на нормальность распределения

H0 - данная выборка  принадлежит нормальному распределению
H1 - данная выборка  не принадлежит нормальному распределению
alpha = 0.05
```{r}
library(sm)
library(nortest)
Data <- read.csv("region.txt", sep = '\t')
wmratio <- Data$Соотношение.мужчин.и.женщин...женщин.на.1000.мужчин.
hist(wmratio, 20)
sm.density(wmratio, model="Normal", xlab = "Выборка", ylab="Функция плотности распределения")
lillie.test(wmratio)
library(moments)
skewness(wmratio)
kurtosis(wmratio)
```
По результатам теста можно видеть, что значение p меньше 0.05, следовательно, отвергается нулевая гипотеза о принадлежности выборки нормальному распределению. По оценкам коэффицентов можно сделать вывод, что распределение скошено вправо и имеется заметный пик.


## Тема № 4: Изучение корреляционной зависимости двух случайных величин

```{r}
Data <- read.csv("region.txt", sep='\t')
x <- Data$Оборот.розничной.торговли..млн.руб..
y <- Data$Обьем.промышленной.продукции..млн.руб..
cor.test(x, y)
```
H0 - корреляция между векторами отсутствует, следовательно коэффициент корреляции равен нулю.
H1 - корреляция между векторами присутствует, следовательно коэффициент корреляции не равен нулю.
Коэффициент корреляции Пирсона больше 0.7, поэтому данные можно считать коррелированными.

```{r}
cor.test(x, y, method = "kendall", conf.level = 0.95)
cor.test(x, y, method = "kendall", conf.level = 0.99)
```

Для a = 0.05 p-value < a, следовательно нулевая гипотеза отвергается.
Для a = 0.01 p-value < a, следовательно нулевая гипотеза отвергается.

```{r}
cor.test(x, y, method = "spearman", conf.level = 0.95)
cor.test(x, y, method = "spearman", conf.level = 0.99)
```
Для a = 0.05 p-value < a, следовательно нулевая гипотеза отвергается.
Для a = 0.01 p-value < a, следовательно нулевая гипотеза отвергается.

## Тема № 5: Коэффициент конкордации

Значение коэффициента конкордации может находится в диапазоне от 0 до 1. Если W=0, считается, что мнения экспертов не согласованны. Если W=1, то оценки экспертов полностью согласованны.
H0 - коэффициент конкордации незначимый.
H1 - коэффициент коркордации значим.
```{r}
library(vegan)
x <- read.table("2.txt", header=FALSE)
kendall.global(x, nperm=999, mult="holm")
```
p < 0.05, значит, нулевая гипотеза отвергается и коэффициент конкордации можно считать значимым.
По данному анализу видно, что коэффициент конкордации равен примерно 0.5 . Это говорит о средней согласованности между экспертами.